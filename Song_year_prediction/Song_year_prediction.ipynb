{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset\n",
        "\n",
        "You can get the data set from the following URL: https://drive.google.com/drive/folders/1ZzDqVRtoNLrDHOB0lmbBwCVkpEZTl3FV?usp=share_link\n",
        "\n"
      ],
      "metadata": {
        "id": "TNdk2TYrkjqQ"
      },
      "id": "TNdk2TYrkjqQ"
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ezhLs4Kp_kL",
        "outputId": "00459c65-1acb-44e2-af61-3dc96752c22e"
      },
      "id": "0ezhLs4Kp_kL",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from audioop import bias\n",
        "import sys\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "np.random.seed(50)\n",
        "NUM_FEATS = 90"
      ],
      "metadata": {
        "id": "vaMTpW_nmU5D"
      },
      "id": "vaMTpW_nmU5D",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Neural Network"
      ],
      "metadata": {
        "id": "tfpGe8onk-zQ"
      },
      "id": "tfpGe8onk-zQ"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "a5e8c9c5",
      "metadata": {
        "id": "a5e8c9c5"
      },
      "outputs": [],
      "source": [
        "class Net(object):\n",
        "\tdef __init__(self, num_layers, num_units):\n",
        "\t\tself.num_layers = num_layers\n",
        "\t\tself.num_units = num_units\n",
        "\n",
        "\t\tself.biases = []\n",
        "\t\tself.weights = []\n",
        "\t\tfor i in range(num_layers):\n",
        "\n",
        "\t\t\tif i==0:\n",
        "\t\t\t\t# Input layer\n",
        "\t\t\t\tself.weights.append(np.random.uniform(-1, 1, size=(NUM_FEATS, self.num_units)))\n",
        "\t\t\telse:\n",
        "\t\t\t\t# Hidden layer\n",
        "\t\t\t\tself.weights.append(np.random.uniform(-1, 1, size=(self.num_units, self.num_units)))\n",
        "\n",
        "\t\t\tself.biases.append(np.random.uniform(-1, 1, size=(self.num_units, 1)))\n",
        "\n",
        "\t\t# Output layer\n",
        "\t\tself.biases.append(np.random.uniform(-1, 1, size=(1, 1)))\n",
        "\t\tself.weights.append(np.random.uniform(-1, 1, size=(self.num_units, 1)))\n",
        "\n",
        "\tdef __call__(self, X):\n",
        "\t\ta = X\n",
        "\t\tself.net = []\n",
        "\t\tself.O = []\n",
        "\t\th = []\n",
        "\t\tself.net.append(a)\n",
        "\t\tfor i,(w,b) in enumerate(zip(self.weights,self.biases)):\n",
        "\t\t\tself.O.append(a)\n",
        "\t\t\th = np.dot(a,w)+b.T\n",
        "\t\t\tself.net.append(h)\n",
        "\t\t\tif i<len(self.weights)-1:\n",
        "\t\t\t\ta = relu(h)\n",
        "\t\t\telse:\n",
        "\t\t\t\ta = sigmoid(h)\n",
        "\t\tself.pred = a\n",
        "\t\treturn self.pred\n",
        "\n",
        "\tdef backward(self, X, y, lamda):\n",
        "\t\tdelta_weights = []\n",
        "\t\tdelta_biases = []\n",
        "\n",
        "\t\tback_outs = []\n",
        "\t\tback_act_outs = []\n",
        "\n",
        "\t\tloss = (self.pred - y)\n",
        "\t\tbatch_size = y.shape[0]\n",
        "\t\tcur_layer = self.num_layers - 1\n",
        "\n",
        "\t\tback_outs.insert(0, loss)\n",
        "\t\tback_act_outs.insert(0, loss)\n",
        "\t\tdelta_weights.insert(0, (np.dot(self.O[cur_layer+1].T, back_outs[0])/batch_size)+lamda * self.weights[cur_layer+1])\n",
        "\t\tdelta_biases.insert(0, (np.array(np.sum(back_outs[0], axis=0).T))/batch_size )\n",
        "\t\tdelta_biases[0] = delta_biases[0].reshape(delta_biases[0].shape[0], 1)\n",
        "\t\tdelta_biases[0] = delta_biases[0] + lamda * self.biases[cur_layer+1]\n",
        "\n",
        "\t\tfor i in range(1, self.num_layers + 1):\n",
        "\t\t\tback_act_outs.insert(0, np.dot(back_outs[0], self.weights[cur_layer + 1].T))\n",
        "\t\t\tback_outs.insert(0, back_act_outs[0] * d_relu(self.O[cur_layer + 1]))\n",
        "\t\t\tdelta_weights.insert(0, (np.dot(self.O[cur_layer].T, back_outs[0])/batch_size)+lamda * self.weights[cur_layer])\n",
        "\t\t\tdelta_biases.insert(0, (np.array(np.sum(back_outs[0], axis=0).T))/batch_size )\n",
        "\t\t\tdelta_biases[0] = delta_biases[0].reshape(delta_biases[0].shape[0], 1)\n",
        "\t\t\tdelta_biases[0] = delta_biases[0] + lamda * self.biases[cur_layer]\n",
        "\t\t\tcur_layer = cur_layer - 1\n",
        "\t\t\n",
        "\t\treturn delta_weights, delta_biases"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Optimizer Class"
      ],
      "metadata": {
        "id": "54KNZEB7mLML"
      },
      "id": "54KNZEB7mLML"
    },
    {
      "cell_type": "code",
      "source": [
        "class Optimizer(object):\n",
        "\tdef __init__(self, learning_rate):\n",
        "\t\tself.learning_rate = learning_rate\n",
        "\n",
        "\tdef step(self, weights, biases, delta_weights, delta_biases):\n",
        "\t\tfor index in range(len(weights)):\n",
        "\t\t\tweights[index] = weights[index] - self.learning_rate * delta_weights[index]\n",
        "\t\t\tbiases[index] = biases[index] - self.learning_rate * delta_biases[index]\n",
        "\t\t\n",
        "\t\treturn weights, biases"
      ],
      "metadata": {
        "id": "Ugpr7QY9mJL-"
      },
      "id": "Ugpr7QY9mJL-",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Loss functions"
      ],
      "metadata": {
        "id": "Zsfwr3Nvl0Xh"
      },
      "id": "Zsfwr3Nvl0Xh"
    },
    {
      "cell_type": "code",
      "source": [
        "def loss_mse(y, y_hat):\n",
        "\treturn np.sum((y-y_hat)**2)/len(y)\n",
        "\n",
        "def loss_regularization(weights, biases):\n",
        "\tloss = 0\n",
        "\tfor i in range(len(weights)):\n",
        "\t\tloss = loss + np.sum(np.square(weights[i])) + np.sum(np.square(biases[i]))\n",
        "\treturn loss\n",
        "\n",
        "def loss_fn(y, y_hat, weights, biases, lamda):\n",
        "\treturn loss_mse(y,y_hat) + (lamda * loss_regularization(weights, biases))\n",
        "\n",
        "def rmse(y, y_hat):\n",
        "\t#root[sum[(y-y_hat)^2/n]\n",
        "\tn = len(y)\n",
        "\treturn np.sqrt((np.sum(y-y_hat)**2)/n)"
      ],
      "metadata": {
        "id": "221unYdbl5Lt"
      },
      "id": "221unYdbl5Lt",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Activations"
      ],
      "metadata": {
        "id": "iJ96h8UOl-IA"
      },
      "id": "iJ96h8UOl-IA"
    },
    {
      "cell_type": "code",
      "source": [
        "def relu(X):\n",
        "\ta = np.maximum(X,0)\n",
        "\treturn a\n",
        "\n",
        "def d_relu(X):\n",
        "\tX[X <= 0] = 0\n",
        "\tX[X > 0] = 1\n",
        "\treturn X\n",
        "\n",
        "def aReLU(z):                 \n",
        "    return np.maximum(0.43*z,z)\n",
        "    \n",
        "def aReLUPrime(z):\n",
        "  a = 1*(z>0)\n",
        "  b = 0.43*(z<0)\n",
        "  c = 0.75*(z==0)\n",
        "  return a+b+c\n",
        "\n",
        "def sigmoid(z):               \n",
        "  return 1.0/(1.0 + np.exp(-z))"
      ],
      "metadata": {
        "id": "JwRVstavmBJk"
      },
      "id": "JwRVstavmBJk",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Data Scaling"
      ],
      "metadata": {
        "id": "_FmrhWvtlQhQ"
      },
      "id": "_FmrhWvtlQhQ"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import preprocessing\n",
        "min_max = preprocessing.MinMaxScaler()"
      ],
      "metadata": {
        "id": "ks5REMlpHcGu"
      },
      "id": "ks5REMlpHcGu",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_data():\n",
        "\t'''\n",
        "\tRead the train, dev, and test datasets\n",
        "\t'''\n",
        "\ttrain_input = pd.read_csv('/content/drive/MyDrive/regression/data/train.csv').iloc[:, 1:].to_numpy()\n",
        "\ttrain_input = min_max.fit_transform(train_input)\n",
        "\tdev_input = pd.read_csv('/content/drive/MyDrive/regression/data/dev.csv').iloc[:, 1:].to_numpy()\n",
        "\tdev_input = min_max.fit_transform(dev_input)\n",
        "\ttest_input = pd.read_csv('/content/drive/MyDrive/regression/data/test.csv').to_numpy()\n",
        "\ttest_input = min_max.fit_transform(test_input)\n",
        "\ttrain_target = pd.read_csv('/content/drive/MyDrive/regression/data/train.csv').iloc[:, 0].to_numpy()\n",
        "\ttrain_target = train_target.reshape(train_target.shape[0], 1)\n",
        "\ttrain_target = min_max.fit_transform(train_target)\n",
        "\tdev_target = pd.read_csv('/content/drive/MyDrive/regression/data/dev.csv').iloc[:, 0].to_numpy()\n",
        "\tdev_target = dev_target.reshape(dev_target.shape[0], 1)\n",
        "\tdev_target = min_max.fit_transform(dev_target)\n",
        "\t\n",
        "\treturn train_input, train_target, dev_input, dev_target, test_input"
      ],
      "metadata": {
        "id": "ecS_tc3vFuP_"
      },
      "id": "ecS_tc3vFuP_",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Training"
      ],
      "metadata": {
        "id": "KjLNMUvGlUu9"
      },
      "id": "KjLNMUvGlUu9"
    },
    {
      "cell_type": "code",
      "source": [
        "def train(net, optimizer, lamda, batch_size, max_epochs,train_input, train_target,dev_input, dev_target, test_input):\n",
        "\n",
        "\tm = train_input.shape[0]\n",
        "\tbatchloss = []\n",
        "\tepoch = []  \n",
        "\n",
        "\tfor e in range(max_epochs):\n",
        "\t\tepoch_loss = 0.\n",
        "\t\tfor i in range(0, m, batch_size):\n",
        "\t\t\tbatch_input = train_input[i:i+batch_size]\n",
        "\t\t\tbatch_target = train_target[i:i+batch_size]\n",
        "\t\t\tpred = net(batch_input)\n",
        "\n",
        "\t\t\t# Compute gradients of loss w.r.t. weights and biases\n",
        "\t\t\tdW, db = net.backward(batch_input, batch_target, lamda)\n",
        "\n",
        "\t\t\t# Get updated weights based on current weights and gradients\n",
        "\t\t\tweights_updated, biases_updated = optimizer.step(net.weights, net.biases, dW, db)\n",
        "\n",
        "\t\t\t# Update model's weights and biases\n",
        "\t\t\tnet.weights = weights_updated\n",
        "\t\t\tnet.biases = biases_updated\n",
        "\n",
        "\t\t\t# Compute loss for the batch\n",
        "\t\t\tbatch_loss = loss_fn(batch_target, pred, net.weights, net.biases, lamda)\n",
        "\t\t\tepoch_loss += batch_loss\n",
        "\t\tepoch.append(e)\n",
        "\t\tbatchloss.append(batch_loss)\n",
        "   \n",
        "\t\tprint('Epoch:',e,'Rmse loss:',rmse(batch_target, pred),'Batch Loss:', batch_loss)\n",
        "\tdev_pred = net(dev_input)\n",
        "\ttest_preds = net(test_input)\n",
        "\tdev_rmse = rmse(dev_target, dev_pred)\n",
        "\tprint('RMSE on dev data: {:.5f}'.format(dev_rmse))\n",
        "\treturn batchloss, epoch, test_preds, dev_target\n",
        "\n",
        " \n",
        " "
      ],
      "metadata": {
        "id": "j84IqC_Ptdog"
      },
      "id": "j84IqC_Ptdog",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "\n",
        "\t# Hyper-parameters \n",
        "\tmax_epochs = 100\n",
        "\tbatch_size = 32\n",
        "\tlearning_rate = 1e-4\n",
        "\tnum_layers = 7\n",
        "\tnum_units = 7\n",
        "\tlamda = 0.03 # Regularization Parameter\n",
        "\n",
        "\ttrain_input, train_target, dev_input, dev_target, test_input = read_data()\n",
        "\tnet = Net(num_layers, num_units)\n",
        "\toptimizer = Optimizer(learning_rate)\n",
        "\tbt_loss, epoch, test_preds, dev_pred = train(\n",
        "\t\tnet, optimizer, lamda, batch_size, max_epochs,\n",
        "\t\ttrain_input, train_target,dev_input, dev_target, test_input\n",
        "\t)\n",
        "\treturn net, bt_loss, epoch, test_preds, dev_target\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "\tnet, bt_loss, epoch, test_preds,dev_pred = main()\n"
      ],
      "metadata": {
        "id": "pBE9lbB4s5Yf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd7d9d4d-b429-4c58-b255-bfd402a379ac"
      },
      "id": "pBE9lbB4s5Yf",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0 Rmse loss: 2.826813806075906 Batch Loss: 9.920897879324366\n",
            "Epoch: 1 Rmse loss: 2.7218540496086043 Batch Loss: 9.827166253305188\n",
            "Epoch: 2 Rmse loss: 2.6375730548169547 Batch Loss: 9.738424697650872\n",
            "Epoch: 3 Rmse loss: 2.5552853908305653 Batch Loss: 9.651281472846788\n",
            "Epoch: 4 Rmse loss: 2.4750622072787367 Batch Loss: 9.565686282339001\n",
            "Epoch: 5 Rmse loss: 2.397001506977693 Batch Loss: 9.481595556395416\n",
            "Epoch: 6 Rmse loss: 2.321187503825746 Batch Loss: 9.398964618595384\n",
            "Epoch: 7 Rmse loss: 2.24768399021791 Batch Loss: 9.317746766515706\n",
            "Epoch: 8 Rmse loss: 2.1765328635276453 Batch Loss: 9.237893689687064\n",
            "Epoch: 9 Rmse loss: 2.1077555777922545 Batch Loss: 9.159356131516946\n",
            "Epoch: 10 Rmse loss: 2.041354648166846 Batch Loss: 9.082084295431711\n",
            "Epoch: 11 Rmse loss: 1.9773179372469964 Batch Loss: 9.006028833622919\n",
            "Epoch: 12 Rmse loss: 1.9156210003281429 Batch Loss: 8.931141616114806\n",
            "Epoch: 13 Rmse loss: 1.8562322342001742 Batch Loss: 8.85737600980494\n",
            "Epoch: 14 Rmse loss: 1.7990966800402464 Batch Loss: 8.784684972194972\n",
            "Epoch: 15 Rmse loss: 1.7441610707638824 Batch Loss: 8.713024742809543\n",
            "Epoch: 16 Rmse loss: 1.6913662659530406 Batch Loss: 8.6423536081586\n",
            "Epoch: 17 Rmse loss: 1.6406487006581132 Batch Loss: 8.572631768277493\n",
            "Epoch: 18 Rmse loss: 1.591941651708691 Batch Loss: 8.503821595389445\n",
            "Epoch: 19 Rmse loss: 1.5451763062690198 Batch Loss: 8.435887754163696\n",
            "Epoch: 20 Rmse loss: 1.5002826860090308 Batch Loss: 8.368796599152232\n",
            "Epoch: 21 Rmse loss: 1.457190409280686 Batch Loss: 8.302516505983416\n",
            "Epoch: 22 Rmse loss: 1.415829328031425 Batch Loss: 8.237017837010542\n",
            "Epoch: 23 Rmse loss: 1.376130046984728 Batch Loss: 8.172273239657883\n",
            "Epoch: 24 Rmse loss: 1.3380243411123627 Batch Loss: 8.10825691870516\n",
            "Epoch: 25 Rmse loss: 1.3014454733629701 Batch Loss: 8.044944597425548\n",
            "Epoch: 26 Rmse loss: 1.266328473940411 Batch Loss: 7.982313826216292\n",
            "Epoch: 27 Rmse loss: 1.232610318335903 Batch Loss: 7.920343615434232\n",
            "Epoch: 28 Rmse loss: 1.2002300522671006 Batch Loss: 7.859013437827874\n",
            "Epoch: 29 Rmse loss: 1.1691288692896622 Batch Loss: 7.798305601591518\n",
            "Epoch: 30 Rmse loss: 1.1392502141320566 Batch Loss: 7.738202314393542\n",
            "Epoch: 31 Rmse loss: 1.1105397644018242 Batch Loss: 7.678687603933952\n",
            "Epoch: 32 Rmse loss: 1.0829454584940865 Batch Loss: 7.619746902374856\n",
            "Epoch: 33 Rmse loss: 1.056417463119565 Batch Loss: 7.5613662356271805\n",
            "Epoch: 34 Rmse loss: 1.0309081317541737 Batch Loss: 7.5035324545074555\n",
            "Epoch: 35 Rmse loss: 1.0063719483923435 Batch Loss: 7.446233338812223\n",
            "Epoch: 36 Rmse loss: 0.9827654870569549 Batch Loss: 7.3894572361137705\n",
            "Epoch: 37 Rmse loss: 0.9600473485567679 Batch Loss: 7.33319332430082\n",
            "Epoch: 38 Rmse loss: 0.9381780697775404 Batch Loss: 7.277431233260639\n",
            "Epoch: 39 Rmse loss: 0.9171200749179589 Batch Loss: 7.222160556404262\n",
            "Epoch: 40 Rmse loss: 0.8968524316392458 Batch Loss: 7.1673739687935125\n",
            "Epoch: 41 Rmse loss: 0.877337370071208 Batch Loss: 7.1130626202235705\n",
            "Epoch: 42 Rmse loss: 0.8585405296793317 Batch Loss: 7.059217257430473\n",
            "Epoch: 43 Rmse loss: 0.8404185655562539 Batch Loss: 7.005829254870045\n",
            "Epoch: 44 Rmse loss: 0.8229407342706458 Batch Loss: 6.9528916751891\n",
            "Epoch: 45 Rmse loss: 0.8060800470573773 Batch Loss: 6.900397352132609\n",
            "Epoch: 46 Rmse loss: 0.7898107858015714 Batch Loss: 6.848339530129399\n",
            "Epoch: 47 Rmse loss: 0.7741091591069716 Batch Loss: 6.7967115292072515\n",
            "Epoch: 48 Rmse loss: 0.7589531192635666 Batch Loss: 6.74550757439217\n",
            "Epoch: 49 Rmse loss: 0.7443210824436394 Batch Loss: 6.694721770073655\n",
            "Epoch: 50 Rmse loss: 0.7301936410522597 Batch Loss: 6.644348317085658\n",
            "Epoch: 51 Rmse loss: 0.7165452939064425 Batch Loss: 6.594382078810158\n",
            "Epoch: 52 Rmse loss: 0.7033557124594625 Batch Loss: 6.544817692186453\n",
            "Epoch: 53 Rmse loss: 0.6906040247737593 Batch Loss: 6.4956507504592285\n",
            "Epoch: 54 Rmse loss: 0.6782755940659755 Batch Loss: 6.446875946874866\n",
            "Epoch: 55 Rmse loss: 0.6663522785348942 Batch Loss: 6.398488935305069\n",
            "Epoch: 56 Rmse loss: 0.6548179532446557 Batch Loss: 6.350485423733655\n",
            "Epoch: 57 Rmse loss: 0.6436612261158996 Batch Loss: 6.302861239450006\n",
            "Epoch: 58 Rmse loss: 0.6328656389145533 Batch Loss: 6.255611772545488\n",
            "Epoch: 59 Rmse loss: 0.6224142110405971 Batch Loss: 6.208733309334496\n",
            "Epoch: 60 Rmse loss: 0.6122950960289326 Batch Loss: 6.162222118240624\n",
            "Epoch: 61 Rmse loss: 0.6025000379223292 Batch Loss: 6.116074610440101\n",
            "Epoch: 62 Rmse loss: 0.5930129994454514 Batch Loss: 6.070286630695451\n",
            "Epoch: 63 Rmse loss: 0.5838203059640819 Batch Loss: 6.024855033224417\n",
            "Epoch: 64 Rmse loss: 0.5749130689097651 Batch Loss: 5.979776070683924\n",
            "Epoch: 65 Rmse loss: 0.5662800732567682 Batch Loss: 5.935046465961309\n",
            "Epoch: 66 Rmse loss: 0.557912245549328 Batch Loss: 5.890662832502713\n",
            "Epoch: 67 Rmse loss: 0.5497959767537921 Batch Loss: 5.846622720914405\n",
            "Epoch: 68 Rmse loss: 0.5419237826872222 Batch Loss: 5.802922948886416\n",
            "Epoch: 69 Rmse loss: 0.5342915162564233 Batch Loss: 5.759559489674122\n",
            "Epoch: 70 Rmse loss: 0.5268866360210414 Batch Loss: 5.716530334746114\n",
            "Epoch: 71 Rmse loss: 0.5196998869989102 Batch Loss: 5.673832673437314\n",
            "Epoch: 72 Rmse loss: 0.5127245404449414 Batch Loss: 5.63146367155148\n",
            "Epoch: 73 Rmse loss: 0.5059546912733794 Batch Loss: 5.5894206191531675\n",
            "Epoch: 74 Rmse loss: 0.4993836900580143 Batch Loss: 5.547701105271844\n",
            "Epoch: 75 Rmse loss: 0.4930027113210411 Batch Loss: 5.506303107612728\n",
            "Epoch: 76 Rmse loss: 0.48680094080363584 Batch Loss: 5.465225282012477\n",
            "Epoch: 77 Rmse loss: 0.4807732179529668 Batch Loss: 5.424466052478806\n",
            "Epoch: 78 Rmse loss: 0.4749137206822021 Batch Loss: 5.3840227472908175\n",
            "Epoch: 79 Rmse loss: 0.4692270759774899 Batch Loss: 5.343894256639628\n",
            "Epoch: 80 Rmse loss: 0.4638400987384968 Batch Loss: 5.304083716134979\n",
            "Epoch: 81 Rmse loss: 0.45861235436977815 Batch Loss: 5.264582565786549\n",
            "Epoch: 82 Rmse loss: 0.4534976700876116 Batch Loss: 5.225388619328536\n",
            "Epoch: 83 Rmse loss: 0.44850730968781477 Batch Loss: 5.186499248065998\n",
            "Epoch: 84 Rmse loss: 0.44366606760715455 Batch Loss: 5.147910292358155\n",
            "Epoch: 85 Rmse loss: 0.43894214792407515 Batch Loss: 5.109618887816479\n",
            "Epoch: 86 Rmse loss: 0.4343205631531823 Batch Loss: 5.071622172066336\n",
            "Epoch: 87 Rmse loss: 0.4298139396778315 Batch Loss: 5.033915527577552\n",
            "Epoch: 88 Rmse loss: 0.4254166030515828 Batch Loss: 4.996497037530984\n",
            "Epoch: 89 Rmse loss: 0.4211405523724575 Batch Loss: 4.959364126284423\n",
            "Epoch: 90 Rmse loss: 0.41697222336883094 Batch Loss: 4.922513686225727\n",
            "Epoch: 91 Rmse loss: 0.41291489069421655 Batch Loss: 4.885942633546672\n",
            "Epoch: 92 Rmse loss: 0.4089603588060799 Batch Loss: 4.849649470344887\n",
            "Epoch: 93 Rmse loss: 0.4051080787870287 Batch Loss: 4.81363165872342\n",
            "Epoch: 94 Rmse loss: 0.40135518338816145 Batch Loss: 4.777887041742085\n",
            "Epoch: 95 Rmse loss: 0.39770278011521365 Batch Loss: 4.742413337010599\n",
            "Epoch: 96 Rmse loss: 0.3941557968220357 Batch Loss: 4.707208070191743\n",
            "Epoch: 97 Rmse loss: 0.390699426234658 Batch Loss: 4.672269663512319\n",
            "Epoch: 98 Rmse loss: 0.3873322972466082 Batch Loss: 4.637595943968137\n",
            "Epoch: 99 Rmse loss: 0.384056250065384 Batch Loss: 4.603185100512182\n",
            "RMSE on dev data: 5.03249\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds = test_preds*(2010-1922)+1922\n",
        "predf=pd.DataFrame(preds,columns=['Predictions'])"
      ],
      "metadata": {
        "id": "tSdWgbKAGbdE"
      },
      "id": "tSdWgbKAGbdE",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predf.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "Q17cvySAWVRs",
        "outputId": "e9b2d841-04a0-49df-ac8a-020c87a19cd3"
      },
      "id": "Q17cvySAWVRs",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Predictions\n",
              "count  5100.000000\n",
              "mean   1992.272859\n",
              "std       0.098088\n",
              "min    1990.997019\n",
              "25%    1992.301932\n",
              "50%    1992.301932\n",
              "75%    1992.301932\n",
              "max    1992.301932"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-24b11ab1-ba43-480f-a7ab-92f0f3a5a3a1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Predictions</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>5100.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>1992.272859</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.098088</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1990.997019</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>1992.301932</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>1992.301932</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>1992.301932</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1992.301932</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-24b11ab1-ba43-480f-a7ab-92f0f3a5a3a1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-24b11ab1-ba43-480f-a7ab-92f0f3a5a3a1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-24b11ab1-ba43-480f-a7ab-92f0f3a5a3a1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#predf.to_csv('/content/drive/MyDrive/testresults.xlsx',index = False)"
      ],
      "metadata": {
        "id": "yWL5t9gKR5y2"
      },
      "id": "yWL5t9gKR5y2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4d6ec1fc",
      "metadata": {
        "id": "4d6ec1fc"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e0538643",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "e0538643",
        "outputId": "e9fdb422-68bf-4b28-8f69-82275e96298c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Loss vs Epoch for batch size = 64')"
            ]
          },
          "metadata": {},
          "execution_count": 130
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.plot(epoch, bt_loss)\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Batchloss')\n",
        "plt.title(\"Loss vs Epoch for batch size = 64\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_input, train_target, dev_input, dev_target, test_input = read_data()\n",
        "\n",
        "print(test_input)\n",
        "print(net)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "leyNawRqzxON",
        "outputId": "abd95706-6330-4ef9-fc84-be3b8483b551"
      },
      "id": "leyNawRqzxON",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[  39.74101   15.36065    8.31249 ...    1.27488  424.14859   21.03857]\n",
            " [  38.01087  -58.38573  -57.76662 ...   75.99168   84.6795   -34.72883]\n",
            " [  36.94025 -101.4874    34.19856 ...   -2.039    -78.53343    2.14682]\n",
            " ...\n",
            " [  35.57222  -33.67729   -9.54801 ...   -2.18869  111.36082    5.32812]\n",
            " [  47.61959    5.5825    26.91684 ...    9.32908   47.60612   -7.99566]\n",
            " [  42.01372   77.59201  -16.88436 ...   18.23418 -127.31246  -11.23811]]\n",
            "<__main__.Net object at 0x7fb02b89bf50>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_preds = test_preds*2010"
      ],
      "metadata": {
        "id": "JKVi-Uj_1B5W"
      },
      "id": "JKVi-Uj_1B5W",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_preds[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t004w94W3-pe",
        "outputId": "1bfaa3c2-da53-4eac-b911-3c2553ebfffc"
      },
      "id": "t004w94W3-pe",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CAXN9yvqGNoV"
      },
      "id": "CAXN9yvqGNoV",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}